# Telemetry-Collector (üõ†Ô∏è Projet DevOps)

## üìå Objectif du projet

Ce projet a √©t√© con√ßu comme un **exercice d'entra√Ænement aux pratiques DevOps modernes**. J'ai combin√© le d√©veloppement d'une application Rust avec la mise en place d'une stack de supervision (Prometheus + Grafana), dans une optique de monitoring, de containerisation et d'automatisation.

Ce projet m'a permis plusieurs choses :

- Booster mes connaissances en **Rust** ainsi qu'en orchestration de services via **Docker Compose**
- Apprendre √† collecter de m√©triques via **Prometheus**
- Afficher des dashboards avec **Grafana**
- L'orchestration de services via **Docker Compose**
- Concevoir une **pipeline CI/CD** (v√©rification de format, tests, ...) pour un projet **Rust**

---

## ‚öôÔ∏è Fonctionnalit√©s du projet

L'application expose des **m√©triques syst√®mes** via un endpoint `/metrics` au format **Prometheus**, incluant :

- L‚Äôutilisation CPU
- L‚Äôutilisation m√©moire
- Le flux r√©seau

Ces m√©triques sont ensuite **scrap√©es par Prometheus** et **visualis√©es dans Grafana** via des dashboards personnalis√©s.

---

## üöÄ Lancement du projet

### üß± Pr√©requis

- Docker & Docker Compose install√©s
- Rust
- Cargo

Il y a 2 mani√®res de d√©marrer le projet :

### ‚ìÇÔ∏è D√©marrage avec le Makefile

√Ä la racine du projet, il y a un **Makefile** qui peut effectuer 5 commandes sur le fichier ```docker/docker-compose.yml```:

- **make up**  
  G√©n√®re la configuration Prometheus puis d√©marre les containers Docker en arri√®re-plan (avec `docker compose -f docker/docker-compose.yml up -d`)  
  et lance ensuite le binaire `telemetry-collector` via `cargo run --release`.

- **make down**  
  Arr√™te et supprime les containers Docker (commande : `docker compose -f docker/docker-compose.yml down`).

- **make logs**  
  Affiche les logs en temps r√©el des containers Docker (commande : `docker compose -f docker/docker-compose.yml logs -f`).

- **make clean**  
  Ex√©cute `make down` puis supprime les volumes Docker associ√©s au projet pour un nettoyage complet.

- **make generate_prometheus**  
  V√©rifie les variables d'environnement d√©finies dans le fichier ```.env``` situ√© √† la racine du projet et adapte le fichier prometheus.yml.

- **make run**  
  Compile et lance localement le binaire `telemetry-collector` en mode release.

### ‚ñ∂Ô∏è D√©marrage avec Docker

Depuis la racine du projet :

```bash
cd docker
docker-compose up --build
```

Cela va :

- Build l‚Äôimage de l‚Äôapplication
- D√©marrer l‚Äôapplication **Telemetry**, **Prometheus** et **Grafana**
- Exposer les ports suivants :
  
  - 8080 : Telemetry
  - 9090 : Prometheus
  - 3000 : Grafana
    - Identifiant : admin
    - Mot de passe : admin
    - **‚ö†Ô∏è La s√©curit√© n'est pas l'objectif de ce projet ! ‚ö†Ô∏è**

### üñ•Ô∏è Acc√®s aux interfaces

- Enpoint Telemetry : ```http://localhost:8080```
- Grafana : ```http://localhost:3000```
- Prometheus : ```http://localhost:9090```

Il est √©galement possible de modifier le port d'√©coute et le chemin du endpoint d'exposition des m√©triques en configurant les variables d'environnement suivantes :

- **TELEMETRY_PORT** (type u16, par exemple 8081)

- **TELEMETRY_METRICS_PATH** (type String, par exemple "/my_metrics")

Ces param√®tres sont g√©r√©s dynamiquement dans le code.

### üìä Grafana

Dans le r√©pertoire ```docker/supervision/grafana``` j'ai pu provisionner grafana avec 3 dashboards stock√©s dans un volume docker afin qu'ils soient inclus par d√©faut lorsque l'utilisateur se connecte.

- Le 1er dashboard affiche l'usage du CPU en fonction du temps.
- Le 2e dashboard affiche le volume de RAM utilis√©e et le volume de RAM libre.
- Le 3e dashboard affiche le volule de d√©bit montant (upload) et le d√©bit descendant (download) sur la derni√®re minute.

Les donn√©es sont rafra√Æchies toutes les 5 secondes.

J‚Äôai √©galement provisionn√© Grafana pour qu‚Äôil se connecte automatiquement √† sa source de donn√©es (Prometheus).

### üîÑ Int√©gration Continue (CI)

J'ai utilis√© **GitHub Actions** pour automatiser les v√©rifications √† chaque modification de la branche main.

Le pipeline ex√©cute les √©tapes suivantes :

- Lint avec Clippy : Analyse statique du code, √©choue en cas d‚Äôavertissements.
- Compilation : Construction du projet avec ```cargo build```.
- Tests : Ex√©cution des tests unitaires et d‚Äôint√©gration avec ```cargo test```.
- Audit de s√©curit√© : V√©rification des d√©pendances connues vuln√©rables via ```cargo audit```.

Chaque √©tape est con√ßue pour garantir la qualit√©, la s√©curit√© et la stabilit√© du code.
